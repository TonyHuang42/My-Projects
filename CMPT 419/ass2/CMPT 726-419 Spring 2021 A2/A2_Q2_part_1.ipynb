{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"A2_Q2_part_1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNFOo8asZAbrejKYCAhUzlj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"m1d6H7X1DPAv"},"source":["# load packages\n","# make sure to install the pacakge \"tqdm\" for the progress bar when training.\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torchvision.utils import save_image\n","from tqdm import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import imageio\n","import matplotlib.image as mpimg\n","from scipy import ndimage\n","\n","path_prefix = \"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvnWAOmtDWlq"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","path_prefix = \"/content/gdrive/MyDrive/CMPT 726-419 Spring 2021 A2\"\n","\n","import sys\n","sys.path.insert(1, path_prefix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t3CXPJA6DYa9"},"source":["class Autoencoder(nn.Module):\n","\n","    def __init__(self,dim_latent_representation=2):\n","\n","        super(Autoencoder,self).__init__()\n","\n","        class Encoder(nn.Module):\n","            def __init__(self, output_size=2):\n","                super(Encoder, self).__init__()\n","                # needs your implementation\n","                self.layer = nn.Linear(28*28, output_size)\n","                pass\n","\n","            def forward(self, x):\n","                # needs your implementation\n","                output = x.view(x.size(0), 28*28)\n","                output = self.layer(output)\n","                return output\n","                pass\n","\n","        class Decoder(nn.Module):\n","            def __init__(self, input_size=2):\n","                super(Decoder, self).__init__()\n","                # needs your implementation\n","                self.layer = nn.Linear(input_size, 28*28)\n","                pass\n","\n","            def forward(self, z):\n","                # needs your implementation\n","                output = self.layer(z)\n","                output = torch.sigmoid(output)\n","                output = output.view(-1, 1, 28, 28)\n","                return output\n","                pass\n","\n","        self.encoder = Encoder(output_size=dim_latent_representation)\n","        self.decoder = Decoder(input_size=dim_latent_representation)\n","\n","    def forward(self,x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-029dYYDrAg"},"source":["from autoencoder_starter import Autoencoder_Trainer\n","\n","LEARNING_RATE = 1e-3\n","EPOCH_NUMBER= 10 # the number of epochs and learning rate can be tuned.\n","\n","autoencoder = Autoencoder(dim_latent_representation=2)\n","trainer = Autoencoder_Trainer(autoencoder_model=autoencoder,learning_rate=LEARNING_RATE,path_prefix=path_prefix)\n","\n","try:\n","    for epoch in range(1, EPOCH_NUMBER + 1):\n","        trainer.train(epoch)\n","        trainer.validate(epoch)\n","except (KeyboardInterrupt, SystemExit):\n","        print(\"Manual Interruption\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDThBnpXDt8I"},"source":["with torch.no_grad():\n","    model = trainer.model\n","    model.eval()\n","    z=[];label=[]\n","    for x,y in trainer.val_loader:\n","\n","        z_ = model.encoder(x.to(trainer.device))\n","        z += z_.cpu().tolist()\n","        label += y.cpu().tolist()\n","    z = np.asarray(z)\n","    label = np.asarray(label)\n","\n","from autoencoder_starter import scatter_plot\n","scatter_plot(latent_representations=z,labels=label)"],"execution_count":null,"outputs":[]}]}