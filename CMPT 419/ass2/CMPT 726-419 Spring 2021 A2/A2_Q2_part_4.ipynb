{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"A2_Q2_part_4.ipynb","provenance":[{"file_id":"1TRfj9qGKmeBqWhnHd5yDtMMzseqXMZQY","timestamp":1618735035434},{"file_id":"1j5kDV_B1jxPCm-XQ3hGurw4I088qCJmm","timestamp":1618734614237},{"file_id":"1JcJAtwosneLBZs-lySkYG_7t2yX9C-sq","timestamp":1618734398752}],"collapsed_sections":[],"authorship_tag":"ABX9TyMx0j08cb0ggFwMjRaK2cFK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"m1d6H7X1DPAv"},"source":["# load packages\n","# make sure to install the pacakge \"tqdm\" for the progress bar when training.\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from torchvision.utils import save_image\n","from tqdm import tqdm\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import imageio\n","import matplotlib.image as mpimg\n","from scipy import ndimage\n","\n","path_prefix = \"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvnWAOmtDWlq"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","path_prefix = \"/content/gdrive/MyDrive/CMPT 726-419 Spring 2021 A2\"\n","\n","import sys\n","sys.path.insert(1, path_prefix)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t3CXPJA6DYa9"},"source":["class Autoencoder(nn.Module):\n","\n","    def __init__(self,dim_latent_representation=2):\n","\n","        super(Autoencoder,self).__init__()\n","\n","        class Encoder(nn.Module):\n","            def __init__(self, output_size=2):\n","                super(Encoder, self).__init__()\n","                # needs your implementation\n","                self.layer1 = nn.Linear(784, 1024)\n","                self.layer2 = nn.ReLU()\n","                self.layer3 = nn.Linear(1024, 10)\n","                pass\n","\n","            def forward(self, x):\n","                # needs your implementation\n","                output = x.view(x.size(0), 784)\n","                output = self.layer1(output)\n","                output = self.layer2(output)\n","                output = self.layer3(output)\n","                return output\n","                pass\n","\n","        class Decoder(nn.Module):\n","            def __init__(self, input_size=2):\n","                super(Decoder, self).__init__()\n","                # needs your implementation\n","                self.layer1 = nn.Linear(10, 1024)\n","                self.layer2 = nn.ReLU()\n","                self.layer3 = nn.Linear(1024, 784)\n","                pass\n","\n","            def forward(self, z):\n","                # needs your implementation\n","                output = self.layer1(z)\n","                output = self.layer2(output)\n","                output = self.layer3(output)\n","                output = torch.sigmoid(output)\n","                output = output.view(-1, 1, 28, 28)\n","                return output\n","                pass\n","\n","        self.encoder = Encoder(output_size=dim_latent_representation)\n","        self.decoder = Decoder(input_size=dim_latent_representation)\n","\n","    def forward(self,x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-029dYYDrAg"},"source":["from autoencoder_starter import Autoencoder_Trainer\n","\n","LEARNING_RATE = 1e-3\n","EPOCH_NUMBER= 10 # the number of epochs and learning rate can be tuned.\n","\n","autoencoder = Autoencoder(dim_latent_representation=2)\n","trainer = Autoencoder_Trainer(autoencoder_model=autoencoder,learning_rate=LEARNING_RATE,path_prefix=path_prefix)\n","\n","try:\n","    for epoch in range(1, EPOCH_NUMBER + 1):\n","        trainer.train(epoch)\n","        trainer.validate(epoch)\n","except (KeyboardInterrupt, SystemExit):\n","        print(\"Manual Interruption\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eiZL7o7mHHHy"},"source":["images = trainer.get_val_set()\n","from autoencoder_starter import display_images_in_a_row\n","for t in np.linspace(0,10,11):\n","  x = np.add((t/10)*images[0], (1-(t/10))*images[1])\n","  if t == 0:\n","    output = x\n","  else:\n","    output = torch.cat((output,x))\n","display_images_in_a_row(output.cpu())"],"execution_count":null,"outputs":[]}]}